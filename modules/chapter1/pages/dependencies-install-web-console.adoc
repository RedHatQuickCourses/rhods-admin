= Installing Dependencies Using the Web Console

As described in the xref::install-general-info.adoc[General Information about Installation] section you may need to install other operators depending on the components and features of OpenShift AI you want to use.  This section will discuss installing and configuring those components.

It is generally recommended to install any dependent operators prior to installing the *Red{nbsp}Hat OpenShift AI* operator.

https://www.redhat.com/en/technologies/cloud-computing/openshift/pipelines[Red{nbsp}Hat OpenShift Pipelines Operator]::
The *Red Hat OpenShift Pipelines Operator* is required if you want to install the *Data Science Pipelines* component.
https://docs.nvidia.com/datacenter/cloud-native/gpu-operator/latest/index.html[NVIDIA GPU Operator]::
The *NVIDIA GPU Operator* is required for GPU support in *Red Hat OpenShift AI*.
https://docs.openshift.com/container-platform/latest/hardware_enablement/psap-node-feature-discovery-operator.html[Node Feature Discovery Operator]::
The *Node Feature Discovery Operator* is a prerequisite for the *NVIDIA GPU Operator*.

This section will discuss the process for installing the dependent operators using the OpenShift Web Console.

== Installation of Data Science Pipelines Dependencies

The Data Science Pipelines component utilizes *Red{nbsp}Hat OpenShift Pipelines* as an execution engine for all pipeline runs, and is required to be installed to take advantage of the Data Science Pipelines component.

The following section discusses installing the *Red{nbsp}Hat OpenShift Pipelines* operator.

=== Lab: Installation of the *Red{nbsp}Hat OpenShift Pipelines* operator

1. Login to Red{nbsp}Hat OpenShift using a user which has the _cluster-admin_ role assigned.

2. Navigate to **Operators** -> **OperatorHub** and search for *Red{nbsp}Hat OpenShift Pipelines*
+
image::pipeline_search.png[width=800]

3. Click on the *Red{nbsp}Hat OpenShift Pipelines* operator. In the pop up window, select the *latest* channel and the most recent version of the pipelines operator. Click on **Install** to open the operator's installation view.
+
image::pipeline_install1.png[width=800]

4. In the `Install Operator` page, select the default values for all the fields and click *Install*.
+
image::pipeline_install2.png[width=800]

5. A window showing the installation progress will pop up.
+ 
image::pipeline_install3.png[width=800]

6. When the installation finishes the operator is ready to be used by *Red{nbsp}Hat OpenShift AI*.
+
image::pipeline_install4.png[width=800]

*Red{nbsp}Hat OpenShift Pipelines* is now successfully installed.

TIP: For assistance installing OpenShift Pipelines from YAML or via ArgoCD, refer to examples found in the https://github.com/redhat-cop/gitops-catalog/tree/main/openshift-pipelines-operator[redhat-cop/gitops-catalog/openshift-pipelines-operator] GitHub repo.

== Lab: Installation of GPU Dependencies

*Red{nbsp}Hat OpenShift AI* makes it easy to expose GPUs to end users to help accelerate training and serving machine learning models.

Currently, *Red{nbsp}Hat OpenShift AI* supports accelerated compute with NVIDIA GPUs using the *NVIDIA GPU Operator* which relies on the *Node Feature Discovery* operator as a dependency.

The following section will discuss the installation and a basic configuration of both *NVIDIA GPU Operator* and the *Node Feature Discovery* operator.

NOTE: *Node Feature Discovery* and the *NVIDIA GPU Operator* can both be installed in a cluster that does not have a node with a GPU.  This can be helpful when you plan to add GPUs at a later date.  If a GPU is not present in the cluster the Dashboard will not present the user an option to deploy using a GPU.

TIP: To view the list of GPU models supported by the *NVIDIA GPU Operator* refer to the https://docs.nvidia.com/datacenter/cloud-native/gpu-operator/latest/platform-support.html#supported-nvidia-gpus-and-systems[Supported NVIDIA GPUs and Systems] docs.

=== Demo: Installation of the *Node Feature Discovery* operator

1. Login to Red{nbsp}Hat OpenShift using a user which has the _cluster-admin_ role assigned.

2. Navigate to **Operators** -> **OperatorHub** and search for *Node Feature Discovery*
+
image::nfd_search.png[width=800]

3. Two options for the *Node Feature Discovery* operator will be available.  Click on the one with *Red Hat* in the top right hand corner, and in the pop up window click on **Install** to open the operator's installation view.
+
IMPORTANT: Make sure you select *Node Feature Discovery* from *Red{nbsp}Hat* NOT the Community version.
+
image::nfd_install1.png[width=800]

4. In the `Install Operator` page, select the option to *Enable Operator recommended cluster monitoring on this Namespace*, and keep all the rest of the parameters at their default values.
+
NOTE: Some of these options may vary slightly depending on your version of OpenShift.  Please refer to the official Node Feature Discovery Documentation for your version of OpenShift for the recommended settings.
+
image::nfd_install2.png[width=800]

5. Click the **Install** button at the bottom of the page to proceed with the installation. A window showing the installation progress will pop up.

6. When the installation finishes, click **View Operator** to configure the `Node Feature Discovery` operator.

7. Click the **Create instance** button for the *NodeFeatureDiscovery* object.
+
image::nfd_configure1.png[width=800]

8. In the `Create NodeFeatureDiscovery` page, leave all fields at their default values, and click the **Create** button.

9. A new set of pods should appear in the **Workloads** -> **Pods** section managed by the *nfd-worker* DaemonSet.  Node Feature Discovery will now be able to automatically detect information about the nodes in the cluster and apply labels to those nodes.
+
image::nfd_verify.png[width=800]

TIP: For assistance installing the Node Feature Discovery Operator from YAML or via ArgoCD, refer to examples found in the https://github.com/redhat-cop/gitops-catalog/tree/main/nfd[redhat-cop/gitops-catalog/nfd] GitHub repo.

*Node Feature Discovery* is now successfully installed and configured.

=== Lab: Installation of the *NVIDIA GPU Operator*

1. Login to Red{nbsp}Hat OpenShift using a user which has the _cluster-admin_ role assigned.

2. Navigate to **Operators** -> **OperatorHub** and search for *NVIDIA GPU Operator*
+
image::gpu_search.png[width=800]

3. Click the `NVIDIA GPU Operator` tile. In the pop up window leave all fields at their default values, and click on **Install** to open the operator's installation view.
+
image::gpu_install1.png[width=800]

4. In the `Install Operator` page, keep all the parameters at their default values, and click the **Install** button at the bottom of the page to proceed with the installation.
+
image::gpu_install2.png[width=800]

5.  A window showing the installation progress will pop up. Wait while the operator finishes installing.

6. When the installation finishes, click the **View Operator** button.

7. Click the **Create instance** button for the *ClusterPolicy* object.
+
image::gpu_configure1.png[width=800]

8. In the `Create ClusterPolicy` page, leave all fields at their default values, and click the **Create** button.

9. After the  *ClusterPolicy* is created, the  *NVIDIA GPU Operator* will update the status *State: ready*.
+
image::gpu_verify1.png[width=800]

10. After the *Red{nbsp}Hat OpenShift AI* operator has been installed and configured, users will be able to see an option for "Number of GPUs" when creating a new workbench.
+
image::gpu_verify2.png[width=800]

NOTE: The Dashboard may initially show "All GPUs are currently in use, try again later." when *Red{nbsp}Hat OpenShift AI*  is first installed.  It may take a few minutes after *Red{nbsp}Hat OpenShift AI* is installed before the GPUs are initially detected.

TIP: The *NVIDIA GPU Operator* supports many advanced use cases such as Multi-Instance GPU (MIG) and Time Slicing that are configurable using the *ClusterPolicy*.  For information about advanced GPU configuration capabilities, refer to the official https://docs.nvidia.com/datacenter/cloud-native/openshift/latest/introduction.html[NVIDIA Documentation].

TIP: For assistance installing the *NVIDIA GPU Operator* from YAML or via ArgoCD, refer to examples found in the https://github.com/redhat-cop/gitops-catalog/tree/main/gpu-operator-certified[redhat-cop/gitops-catalog/gpu-operator-certified] GitHub repo.
