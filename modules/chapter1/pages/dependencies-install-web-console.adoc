= Installing Dependencies Using the Web Console

As described in the xref::install-general-info.adoc[General Information about Installation] section, you may need to install other operators depending on the components and features of OpenShift AI you want to use.  This section will discuss about installing and configuring those components.

It is generally recommended to install any dependent operators prior to installing the *Red{nbsp}Hat OpenShift AI* operator.

// This section given below is the same as in the previous chapter. Is the whole section with explanation required here again?

https://www.redhat.com/en/technologies/cloud-computing/openshift/serverless[Red{nbsp}Hat OpenShift Serverless Operator]::
The *Red{nbsp}Hat OpenShift Serverless Operator* is required if you want to install the *single-model serving platform component*.

https://catalog.redhat.com/software/container-stacks/detail/5ec53e8c110f56bd24f2ddc4[Red{nbsp}Hat OpenShift Service Mesh Operator]::
The *Red{nbsp}Hat OpenShift Serverless Operator* is required if you want to install the *single-model serving platform component*.

https://developers.redhat.com/articles/2021/06/18/authorino-making-open-source-cloud-native-api-security-simple-and-flexible[Red{nbsp}Hat OpenShift Authorino (technical preview) Operator]::
The *Red{nbsp}Hat Authorino Operator* is required to support enforcing authentication policies in *Red Hat OpenShift AI*.

https://docs.nvidia.com/datacenter/cloud-native/gpu-operator/latest/index.html[NVIDIA GPU Operator]::
The *NVIDIA GPU Operator* is required for GPU support in *Red Hat OpenShift AI*.
https://docs.openshift.com/container-platform/latest/hardware_enablement/psap-node-feature-discovery-operator.html[Node Feature Discovery Operator]::
The *Node Feature Discovery Operator* is a prerequisite for the *NVIDIA GPU Operator*.

This section will discuss the process for installing the dependent operators using the OpenShift Web Console.

== Installation of Red Hat OpenShift Serverless Dependencies

The following section discusses installing the *Red{nbsp}Hat OpenShift Serverless* operator.

=== Lab: Installation of the *Red{nbsp}Hat OpenShift Serverless* operator

1. Login to Red{nbsp}Hat OpenShift using a user which has the _cluster-admin_ role assigned.

2. Navigate to **Operators** -> **OperatorHub** and search for *Red{nbsp}Hat OpenShift Serverless*
+
image::serverless_operator_search.png[width=800]

3. Click on the *Red{nbsp}Hat OpenShift Serverless* operator. In the pop up window, select the *stable* channel and the most recent version of the serverless operator. Click on **Install** to open the operator's installation view.
+
image::serverless_operator_install1.png[width=600]

4. In the `Install Operator` page, select the default values for all the fields and click *Install*.
+
image::serverless_operator_install2.png[width=800]

5. A window showing the installation progress will pop up.
+ 
image::serverless_operator_install3.png[width=800]

6. When the installation finishes the operator is ready to be used by *Red{nbsp}Hat OpenShift AI*.
+
image::serverless_operator_install4.png[width=800]

*Red{nbsp}Hat OpenShift Serverless* is now successfully installed.

== Installation of Red Hat OpenShift Service Mesh

The following section discusses installing the *Red{nbsp}Hat OpenShift Service Mesh* operator.

=== Lab: Installation of the *Red{nbsp}Hat OpenShift Service Mesh* operator

1. Login to Red{nbsp}Hat OpenShift using a user which has the _cluster-admin_ role assigned.

2. Navigate to **Operators** -> **OperatorHub** and search for *Red{nbsp}Hat OpenShift Service Mesh*
+
image::servicemesh_operator_search.png[width=800]

3. Click on the *Red{nbsp}Hat OpenShift Service Mesh* operator. In the pop up window, select the *stable* channel and the most recent version of the server mesh operator. Click on **Install** to open the operator's installation view.
+
image::servicemesh_operator_install1.png[width=600]

4. In the `Install Operator` page, select the default values for all the fields and click *Install*.
+
image::servicemesh_operator_install2.png[width=800]

5. A window showing the installation progress will pop up.
+ 
image::servicemesh_operator_install3.png[width=800]

6. When the installation finishes the operator is ready to be used by *Red{nbsp}Hat OpenShift AI*.
+
image::servicemesh_operator_install4.png[width=800]

*Red{nbsp}Hat OpenShift Service Mesh* is now successfully installed.

== Installation of Red Hat Authorino Dependencies

=== Lab: Installation of the *Red{nbsp}Hat Authorino* operator

1. Login to Red{nbsp}Hat OpenShift using a user which has the _cluster-admin_ role assigned.

2. Navigate to **Operators** -> **OperatorHub** and search for *Red{nbsp}Hat Authorino
+
image::authorino_operator_search.png[width=800]

3. Click on the *Red{nbsp}Hat Authorino * operator. In the pop up window, select the *stable* channel and the most recent version of the serverless operator. Click on **Install** to open the operator's installation view.
+
image::authorino_operator_install1.png[width=600]

4. In the `Install Operator` page, select the default values for all the fields and click *Install*.
+
image::authorino_operator_install2.png[width=800]

5. A window showing the installation progress will pop up.
+ 
image::authorino_operator_install3.png[width=800]

6. When the installation finishes the operator is ready to be used by *Red{nbsp}Hat OpenShift AI*.
+
image::authorino_operator_install4.png[width=800]

*Red{nbsp}Hat Authorino* is now successfully installed.

The following section discusses installing the *Red{nbsp}Hat - Authorino* operator.

== Lab: Installation of GPU Dependencies

*Red{nbsp}Hat OpenShift AI* makes it easy to expose GPUs to end users to help accelerate training and serving machine learning models.

Currently, *Red{nbsp}Hat OpenShift AI* supports accelerated compute with NVIDIA GPUs using the *NVIDIA GPU Operator* which relies on the *Node Feature Discovery* operator as a dependency.

The following section will discuss the installation and a basic configuration of both *NVIDIA GPU Operator* and the *Node Feature Discovery* operator.

NOTE: *Node Feature Discovery* and the *NVIDIA GPU Operator* can both be installed in a cluster that does not have a node with a GPU.  This can be helpful when you plan to add GPUs at a later date.  If a GPU is not present in the cluster, the Dashboard will not present the user an option to deploy using a GPU.

TIP: To view the list of GPU models supported by the *NVIDIA GPU Operator* refer to the https://docs.nvidia.com/datacenter/cloud-native/gpu-operator/latest/platform-support.html#supported-nvidia-gpus-and-systems[Supported NVIDIA GPUs and Systems] docs.

=== Demo: Installation of the *Node Feature Discovery* operator

1. Login to Red{nbsp}Hat OpenShift using a user which has the _cluster-admin_ role assigned.

2. Navigate to **Operators** -> **OperatorHub** and search for *Node Feature Discovery*
+
image::node_feature_discovery_search.png[width=800]

3. Two options for the *Node Feature Discovery* operator will be available.  Click on the one with *Red Hat* in the top right hand corner, and in the pop up window click on **Install** to open the operator's installation view.
+
IMPORTANT: Make sure you select *Node Feature Discovery* from *Red{nbsp}Hat* NOT the Community version.
+
image::node_feature_discovery_install1.png[width=800]

4. In the `Install Operator` page, select the option to *Enable Operator recommended cluster monitoring on this Namespace*, and keep all the rest of the parameters at their default values.
+
NOTE: Some of these options may vary slightly depending on your version of OpenShift.  Please refer to the official Node Feature Discovery Documentation for your version of OpenShift for the recommended settings.
+
image::node_feature_discovery_install2.png[width=800]

5. Click the **Install** button at the bottom of the page to proceed with the installation. A window showing the installation progress will pop up.

6. When the installation finishes, click **View Operator** to configure the `Node Feature Discovery` operator.

7. Click the **Create instance** button for the *NodeFeatureDiscovery* object.
+
image::node_feature_discovery_instance1.png[width=800]

8. In the `Create NodeFeatureDiscovery` page, leave all fields at their default values, and click the **Create** button.

9. A new set of pods should appear in the **Workloads** -> **Pods** section managed by the *nfd-worker* DaemonSet.  Node Feature Discovery will now be able to automatically detect information about the nodes in the cluster and apply labels to those nodes.
+
image::nvidia_gpu_pods.png[width=800]

TIP: For assistance in installing the Node Feature Discovery Operator from YAML or via ArgoCD, refer to examples found in the https://github.com/redhat-cop/gitops-catalog/tree/main/nfd[redhat-cop/gitops-catalog/nfd] GitHub repo.

*Node Feature Discovery* is now successfully installed and configured.

=== Lab: Installation of the *NVIDIA GPU Operator*

1. Login to Red{nbsp}Hat OpenShift using a user which has the _cluster-admin_ role assigned.

2. Navigate to **Operators** -> **OperatorHub** and search for *NVIDIA GPU Operator*
+
image::nvidia_operator_search.png[width=800]

3. Click the `NVIDIA GPU Operator` tile. In the pop up window leave all fields at their default values, and click on **Install** to open the operator's installation view.
+
image::nvidia_gpu_operator1.png[width=800]

4. In the `Install Operator` page, keep all the parameters at their default values, and click the **Install** button at the bottom of the page to proceed with the installation.
+
image::nvidia_gpu_operator2.png[width=800]

5.  A window showing the installation progress will pop up. Wait while the operator finishes installing.

6. When the installation finishes, click the **View Operator** button.

7. Click the **Create instance** button for the *ClusterPolicy* object.
+
image::nvidia_gpu_instance1.png[width=800]

8. In the `Create ClusterPolicy` page, leave all fields at their default values, and click the **Create** button.

9. After the  *ClusterPolicy* is created, the  *NVIDIA GPU Operator* will update the status *State: ready*.
+
image::nvidia_gpu_instance2.png[width=800]

10. After the *Red{nbsp}Hat OpenShift AI* operator has been installed and configured, users will be able to see an option for "Number of GPUs" when creating a new workbench.
+
image::gpu_verify2.png[width=800]

NOTE: The Dashboard may initially show "All GPUs are currently in use, try again later." when *Red{nbsp}Hat OpenShift AI*  is first installed.  It may take a few minutes after *Red{nbsp}Hat OpenShift AI* is installed before the GPUs are initially detected.

TIP: The *NVIDIA GPU Operator* supports many advanced use cases such as Multi-Instance GPU (MIG) and Time Slicing that are configurable using the *ClusterPolicy*.  For information about advanced GPU configuration capabilities, refer to the official https://docs.nvidia.com/datacenter/cloud-native/openshift/latest/introduction.html[NVIDIA Documentation].

TIP: For assistance installing the *NVIDIA GPU Operator* from YAML or via ArgoCD, refer to examples found in the https://github.com/redhat-cop/gitops-catalog/tree/main/gpu-operator-certified[redhat-cop/gitops-catalog/gpu-operator-certified] GitHub repo.
