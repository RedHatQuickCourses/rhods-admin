= Installing Dependencies Using the Web Console

As described in the xref::install-general-info.adoc[General Information about Installation] section you may need to install other operators depending on the components and features of OpenShift AI you want to use.  This section will discuss installing and configuring those components.

It is generally recommended to install any dependent operators prior to installing the *Red{nbsp}Hat OpenShift Data Science* operator.


https://www.redhat.com/en/technologies/cloud-computing/openshift/pipelines[Red{nbsp}Hat OpenShift Pipelines Operator]::
The *Red Hat OpenShift Pipelines Operator* is required if you want to install the *Data Science Pipelines* component.
https://docs.nvidia.com/datacenter/cloud-native/gpu-operator/latest/index.html[NVIDIA GPU Operator]::
The *NVIDIA GPU Operator* is required for GPU support in *Red Hat OpenShift AI*.
https://docs.openshift.com/container-platform/4.13/hardware_enablement/psap-node-feature-discovery-operator.html[Node Feature Discovery Operator]::
The *Node Feature Discovery Operator* is a prerequisite for the *NVIDIA GPU Operator*.

This section will discuss the process for installing the dependent operators using the OpenShift Web Console.

== Installation of Data Science Pipelines Dependencies

The Data Science Pipelines component utilizes *Red{nbsp}Hat OpenShift Pipelines* as an execution engine for all pipeline runs, and is required to be installed to take advantage of the Data Science Pipelines component.

The following section discusses installing the *Red{nbsp}Hat OpenShift Pipelines* operator.

=== Demo: Installation of the *Red{nbsp}Hat OpenShift Pipelines* operator

1. Login to Red{nbsp}Hat OpenShift using a user which has the _cluster-admin_ role assigned.

2. Navigate to **Operators** -> **OperatorHub** and search for *Red{nbsp}Hat OpenShift Pipelines*
+
image::pipeline_search.png[width=800]

3. Click on the *Red{nbsp}Hat OpenShift Pipelines* operator and in the pop up window click on **Install** to open the operator's installation view.
+
image::pipeline_install1.png[width=800]

4. In the installation view choose the *Update{nbsp}channel* and the *Update{nbsp}approval* parameters. You can accept the default values. The *Installation{nbsp}mode* and the *Installed{nbsp}namespace* parameters are fixed.
+
image::pipeline_install2.png[width=800]

5. Click on the **Install** button at the bottom of to view the to proceed with the installation. A window showing the installation progress will pop up.
+ 
image::pipeline_install3.png[width=800]

6. When the installation finishes the operator is ready to be used by *Red{nbsp}Hat OpenShift AI*.
+
image::pipeline_install4.png[width=800]

*Red{nbsp}Hat OpenShift Pipelines* is now successfully installed.

TIP: For assistance installing OpenShift Pipelines from YAML or via ArgoCD, refer to examples found in the [redhat-cop/gitops-catalog/openshift-pipelines-operator](https://github.com/redhat-cop/gitops-catalog/tree/main/openshift-pipelines-operator) GitHub repo.

== Installation of GPU Dependencies

*Red{nbsp}Hat OpenShift AI* makes it easy to expose GPUs to end users to help accelerate training and serving machine learning models.

Currently, *Red{nbsp}Hat OpenShift AI* supports accelerated compute with NVIDIA GPUs using the *NVIDIA GPU Operator* which relies on the *Node Feature Discovery* operator as a dependency.

The following section will discuss the installation and a basic configuration of both *NVIDIA GPU Operator* and the *Node Feature Discovery* operator.

NOTE: *Node Feature Discovery* and the *NVIDIA GPU Operator* can both be installed in a cluster that does not have a node with a GPU.  This can be helpful when you plan to add GPUs at a later date.  If a GPU is not present in the cluster the Dashboard will not present the user an option to deploy using a GPU.

TIP: To view the list of GPU models supported by the *NVIDIA GPU Operator* refer to the https://docs.nvidia.com/datacenter/cloud-native/gpu-operator/latest/platform-support.html#supported-nvidia-gpus-and-systems[Supported NVIDIA GPUs and Systems] docs.

=== Demo: Installation of the *Node Feature Discovery* operator

1. Login to Red{nbsp}Hat OpenShift using a user which has the _cluster-admin_ role assigned.

2. Navigate to **Operators** -> **OperatorHub** and search for *Node Feature Discovery*
+
image::nfd_search.png[width=800]

3. Two options for the *Node Feature Discovery* operator will be available.  Click on the one with *Red Hat* in the top right hand corner and in the pop up window click on **Install** to open the operator's installation view.
+
IMPORTANT: Make sure you select *Node Feature Discovery* from *Red{nbsp}Hat* not the *Community* version.
+
image::nfd_install1.png[width=800]

4. In the installation view check the box to *Enable Operator recommended cluster monitoring on this Namespace* and the *Update{nbsp}approval* parameters if desired.  Leave the *Update channel*, *Version*, and the *Installed{nbsp}Namespace* parameters as the default options.
+
NOTE: Some of these options may vary slightly depending on your version of OpenShift.  Please refer to the official Node Feature Discovery Documentation for your version of OpenShift for the recommended settings.
+
image::nfd_install2.png[width=800]

5. Click on the **Install** button at the bottom of to view the to proceed with the installation. A window showing the installation progress will pop up.
+ 
image::nfd_install3.png[width=800]

6. When the installation finishes the operator to be configured.  Click the button to **View Operator**.
+
image::nfd_install4.png[width=800]

7. Click the **Create instance** button for the *NodeFeatureDiscovery* object.
+
image::nfd_configure1.png[width=800]

8. Leave the default options for *NodeFeatureDiscovery* selected, and click the **Create** button.
+
image::nfd_configure2.png[width=800]

9. A new set of pods should appear in the **Workloads** -> **Pods** section managed by the nfd-worker DaemonSet.  Node Feature Discovery will now be able to automatically detect information about the nodes in the cluster and apply labels to those nodes.
+
image::nfd_verify.png[width=800]

TIP: For assistance installing the Node Feature Discovery Operator from YAML or via ArgoCD, refer to examples found in the [redhat-cop/gitops-catalog/nfd](https://github.com/redhat-cop/gitops-catalog/tree/main/nfd) GitHub repo.

*Node Feature Discovery* is now successfully installed and configured.

=== Demo: Installation of the *NVIDIA GPU Operator*

1. Login to Red{nbsp}Hat OpenShift using a user which has the _cluster-admin_ role assigned.

2. Navigate to **Operators** -> **OperatorHub** and search for *NVIDIA GPU Operator*
+
image::gpu_search.png[width=800]

3. Click the NVIDIA GPU Operator tile and in the pop up window click on **Install** to open the operator's installation view.
+
image::gpu_install1.png[width=800]

4. In the installation view update the *Update channel* and *Update{nbsp}approval* parameters if desired.  Leave the *Installation{nbsp}mode* and the *Installed{nbsp}namespace* parameters as the default options.
+
image::gpu_install2.png[width=800]

5. Click on the **Install** button at the bottom of to view the to proceed with the installation. A window showing the installation progress will pop up.
+ 
image::gpu_install3.png[width=800]

6. When the installation finishes the operator to be configured.  Click the button to **View Operator**.
+
image::gpu_install4.png[width=800]

7. Click the **Create instance** button for the *ClusterPolicy* object.
+
image::gpu_configure1.png[width=800]

8. Leave the default options for *ClusterPolicy* selected, and click the **Create** button.
+
image::gpu_configure2.png[width=800]

9. After the gpu-cluster-policy *ClusterPolicy* is created, the  *NVIDIA GPU Operator* will update the status of the *ClusterPolicy* to *State: ready*.
+
image::gpu_verify1.png[width=800]

10. After the *Red{nbsp}Hat OpenShift Data Science* operator has been installed and configured, users will be able to see an option for "Number of GPUs" when creating a new workbench.
+
image::gpu_verify2.png[width=800]

NOTE: The Dashboard may initially show "All GPUs are currently in use, try again later." when *Red{nbsp}Hat OpenShift AI*  is first installed.  It may take a few minutes after *Red{nbsp}Hat OpenShift AI* is installed before the GPUs are initially detected.

TIP: The *NVIDIA GPU Operator* supports many advanced use cases such as Multi-Instance GPU (MIG) and Time Slicing that are configurable using the *ClusterPolicy*.  For information about advanced GPU configuration capabilities, refer to the official https://docs.nvidia.com/datacenter/cloud-native/openshift/latest/introduction.html[NVIDIA Documentation].

TIP: For assistance installing the *NVIDIA GPU Operator* from YAML or via ArgoCD, refer to examples found in the [redhat-cop/gitops-catalog/gpu-operator-certified](https://github.com/redhat-cop/gitops-catalog/tree/main/gpu-operator-certified) GitHub repo.
