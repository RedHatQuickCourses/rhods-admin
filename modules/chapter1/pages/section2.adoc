= Installation using the Web Console

As mentioned earlier,  *Red{nbsp}Hat Openshift Data Science* is available as an operator via Openshift Operator Hub. In the following demonstration you will install the *Red{nbsp}Hat Openshift Data Science operator V2* using the Openshift web console.


== Demo: Installation of the Red{nbsp}Hat Openshift Data Science operator

IMPORTANT: The installation requires a user with the _cluster-admin_ role


1. Login to the Red Hat Openshift using a user which has the _cluster-admin_ role assigned.

2. Navigate to **Operators** -> **OperatorHub** and search for *Red{nbsp}Hat Openshift Data Science*.
+
image::rhods_install1.png[width=800]


3. Click on the Red{nbsp}Hat Openshift Data Science operator and in the pop up window click on **Install** to open the operator's installation view.
+
IMPORTANT: Make sure you select *Openshift Data Science* from *Red{nbsp}Hat* not the *Community* version.
+
image::rhods_install2.png[width=800]

4. In the installation view window choose the _alpha_ *Update Channel*, _Automatic_ *Update approval* and keep the default *Installed Namespace*. Click on the *Install* button to start the installation.
+
image::rhods2-install-view.png[width=800]
+
Operator Installation progress window will pop up. The installation may take a couple of minutes.
+
image::rhods2-install.png[width=800]

5. When the operator's installation is finished, click on the *Create DataScienceCluster* button to create and configure your cluster.
+
image::rhods2-install-finished.png[width=800]

6. In the *Create DataScienceCluster* view choose a name for your cluster and select components that will be installed and managed by the operator. There are following components to choose from:
+
CodeFlare::
Data Science Pipelines::
KServe::
ModelMeshServing::
Ray::
Worbenches::


You can choose to create the DataScienceCluster using either the _Form view_ or the _YAML View_. The _Form view_ is a web based form and 'YAML view' is based on a YAML definition of the DataScience cluster resource. The following picture shows the _Form view_. 
+
image::rhods2-create-cluster.png[width=800]
+
If you choose the _YAML view_, you are presented with a template of the YAML DataScienceCluster resource definition similar to the one below.
+
----
apiVersion: datasciencecluster.opendatahub.io/v1
kind: DataScienceCluster
metadata:
  name: default 
  labels:
    app.kubernetes.io/name: datasciencecluster
    app.kubernetes.io/instance: default
    app.kubernetes.io/part-of: rhods-operator
    app.kubernetes.io/managed-by: kustomize
    app.kubernetes.io/created-by: rhods-operator
spec:
  components:
    codeflare:
      managementState: Removed  <1>
    dashboard:
      managementState: Managed  <2>
    datasciencepipelines:
      managementState: Managed
    kserve:
      managementState: Removed
    modelmeshserving:
      managementState: Managed
    ray:
      managementState: Removed
    workbenches:
      managementState: Managed
----
<1> For components you *do not* want to install use *Removed*
<2> For components you *want* to install and manage by the operator use *Managed*
+
After naming the cluster and choosing the components you wish the operator to install and manage click on the *Create* button.

7. After creating the DataScienceCluster a view showing the DataScienceCluster details opens. Wait until the status of the cluster reads *Phase: Ready*
+
image::rhods2-clusters.png[width=800]

8. The operator should be installed and configured now. 
In the applications window in the right upper corner of the screen the *Red{nbsp}Hat Openshift Data Science* dashboard should be available.
+
image::rhods_verify1.png[width=800]
+ 
9. Click on the *Red{nbsp}Hat Openshift Data Science* button to log in to the *Red{nbsp}Hat Openshift Data Science*.
+
image::rhods_verify2.png[width=800]
+
IMPORTANT: It may take a while to start all the service pods hence the login window may not be accessible immediately. If you are getting an error, check the status of the pods in the project *redhat-ods-applications*.
Navigate to *Workloads* -> *pods* and select project *redhat-ods-applications*. All pods must be running and be ready. If they are not, wait until they become running and ready.
+
image::rhods_verify_pods.png[width=800] 


== Installation of other operators required by Openshift Data Science


As described in the xref::section1.adoc[General Information about Installation] section you may need to install other operators depending on the components and features of Openshift Data Science you want to use:

* https://www.redhat.com/en/technologies/cloud-computing/openshift/pipelines[Red{nbsp}Hat Openshift Pipelines Operator]
* https://docs.nvidia.com/datacenter/cloud-native/gpu-operator/latest/index.html[NVIDIA GPU Operator]
* https://docs.openshift.com/container-platform/4.13/hardware_enablement/psap-node-feature-discovery-operator.html[Node Feature Discovery Operator]


The following demonstration shows the installation of the https://www.redhat.com/en/technologies/cloud-computing/openshift/pipelines[Red{nbsp}Hat Openshift Pipelines Operator]. Installation of the two other operators is very similar.

=== Demo: Installation of the *Red{nbsp}Hat Openshift Pipelines* operator

1. Login to Red{nbsp}Hat Openshift using a user which has the _cluster-admin_ role assigned.
2. Navigate to **Operators** -> **OperatorHub** and search for *Red{nbsp}Hat Openshift Pipelines*
+
image::pipeline_search.png[width=800]

3. Click on the *Red{nbsp}Hat Openshift Pipelines* operator and in the pop up window click on **Install** to open the operator's installation view.
+
image::pipeline_install1.png[width=800]


4. In the installation view choose the *Update{nbsp}channel* and the *Update{nbsp}approval* parameters. You can accept the default values. The *Installation{nbsp}mode* and the *Installed{nbsp}namespace* parameters are fixed.
+
image::pipeline_install2.png[width=800]

5. Click on the **Install** button at the bottom of to view the to proceed with the installation. A window showing the installation progress will pop up.
+ 
image::pipeline_install3.png[width=800]

6. When the installation finishes the operator is ready to be used by the *Red{nbsp}Hat Openshift Data Science*.
+
image::pipeline_install4.png[width=800]

